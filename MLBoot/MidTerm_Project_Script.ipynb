{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLBook Camp : Mid-Term Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the libraries required to run this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET \n",
    "________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Description:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data used in this project is from the Reddit forum ChangeMyView ([data](https://panda.uni-paderborn.de/pluginfile.php/1752026/mod_resource/content/1/test-data-prepared.json)). The online interactions between users with respect to any articles or news generally tend to turn into ad-hominem|(rude) posts. Due to such reasons, these conversations/comments are annotated by the forum. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification goal here is to be able to predict the ad-hominem attacks in an online interaction between users, given a preceding dialogue. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before feeding the input to text pre-processing, the preceding posts are merged. \n",
    "The text preprocessing is done via spacy. \n",
    "Punctuations,spaces, urls, stop words are removed from the original text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_file(path_to_file):\n",
    "    with open('C:/Users/Amruta/Desktop/MLBoot/train-data-prepared.json', \"r\") as data_file:\n",
    "        dialogues = json.load(data_file)\n",
    "    return dialogues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The preceding posts (dialogues) are merged to get the sequential information of the dialogues.\n",
    "\n",
    "def merge_dialogue_texts(dialogues):\n",
    "    preceding_posts_body = []\n",
    "    full_dialogue_body = ''\n",
    "    post_content = ''\n",
    "\n",
    "    for dialogue in dialogues:\n",
    "        for post in dialogue['preceding_posts']:\n",
    "            post_content = post['body'].replace('\\n', ' ').strip()\n",
    "            post_content = post_content + ' ' if post_content.endswith(('?', '.', '!')) else post_content + '. '\n",
    "            full_dialogue_body = full_dialogue_body + post_content\n",
    "        preceding_posts_body.append(full_dialogue_body)\n",
    "        full_dialogue_body = ''\n",
    "\n",
    "    return preceding_posts_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning : Punctuations,spaces, urls, stop words are removed from the original text.\n",
    "\n",
    "def clean_dialogue_text(dialogue_text):\n",
    "    parsed_dialogue_text = nlp(dialogue_text)\n",
    "    tokenized_dialogue_clean_text = []\n",
    "    for dialogue_token in parsed_dialogue_text:\n",
    "        if (not dialogue_token.is_punct and\n",
    "            not dialogue_token.is_space and\n",
    "            not dialogue_token.like_url and\n",
    "                not dialogue_token.is_stop):\n",
    "            tokenized_dialogue_clean_text.append(dialogue_token.text)\n",
    "    return tokenized_dialogue_clean_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section I have performed the below tasks:\n",
    "\n",
    "\n",
    "- Features Analysis :\n",
    " \n",
    "The majority of our features are keyword counts which are helpful to detect ad hominem inducing dialogues. The sequential structure of the posts is also used to extract sequential flag features.\n",
    "\n",
    "    - There are 12 defined features used for this task and the top 150 features are taken from TfidfVectorizer.\n",
    "    - The keyword count (feature name starts with “no_of_”)features are taken by merging and cleaning the posts.Then the count of those dialogues is taken.\n",
    "    - The keyword count features are taken on the merged and cleaned dialogues and the sequential features are taken on the raw data.\n",
    "    - The 12 defined features (including sequential features) are as follows:\n",
    "        - no_of_uppercase_words: This feature contains the count of all the uppercase words.\n",
    "        - no_of_nazi_words: This feature contains the count of the“nazi” keyword.\n",
    "        - no_of_rape_words: This feature contains the count of the “rape” keyword.\n",
    "        - no_of_racist_words: This feature contains the count of the “racist” keyword.\n",
    "        - no_of_propaganda_words: This feature contains the count of the “propaganda” keyword.\n",
    "        - no_of_vulgar_words: This feature contains the count of the vulgar keywords.\n",
    "        - no_of_missing_evidence_words: This feature contains the count of the keywords “unsupported”,“unsubstantiated”.\n",
    "        - no_of_fall_argument_words: This feature contains the count of the keywords “fallacy”, “fallacious”.\n",
    "        - no_of_read_words: This feature contains the count of the keywords “reading”, “read”.\n",
    "        - no_of_troll_words: This feature contains the count of the keywords “troll”, “trolls”, “trolling”.\n",
    "        - flag_inc_vulgar_words: This feature is set to 1 if the vulgar words in the second preceding post are greater than the first preceding post else 0.\n",
    "        - flag_inc_uppercase_words: This feature is set to 1 if the uppercase words in the second preceding post are greater than the first preceding post else 0.\n",
    "\n",
    "- Dialogue Modelling : \n",
    "    - Model the dialogical/sequential information leading to ad-hominem posts.\n",
    "    - The sequential/dialogical structure is modeled using the flag features.\n",
    "    - The flag features (feature name starts with “flag_inc_”) check the two preceding posts and set the flags accordingly.\n",
    "    \n",
    "- Missing Features Analysis.\n",
    "- Analysis of Target features.\n",
    "- Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dialogue data pre-processing \n",
    "def preprocess_text_data(dialogue_text_list):\n",
    "    dialogue_text_list = [clean_dialogue_text(sentence) for sentence in dialogue_text_list]\n",
    "    dialogue_text_list = [' '.join(document) for document in dialogue_text_list]\n",
    "    return dialogue_text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function returns the number of uppercase_words\n",
    "\n",
    "def count_uppercase_words(dialogues):\n",
    "    no_of_uppercase_words = 0\n",
    "    no_of_uppercase_words_list = []\n",
    "    for merged_cleaned_dialogue in dialogues:\n",
    "        for dialogue_token in merged_cleaned_dialogue.split():\n",
    "            if dialogue_token.isupper():\n",
    "                no_of_uppercase_words += 1\n",
    "        no_of_uppercase_words_list.append(no_of_uppercase_words)\n",
    "        no_of_uppercase_words = 0\n",
    "\n",
    "    return no_of_uppercase_words_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function checks for lowercase_words and returns its count\n",
    "\n",
    "def count_keyword(merged_cleaned_dialogues, keyword):\n",
    "    keyword_count = 0\n",
    "    keyword_count_list = []\n",
    "    for merged_cleaned_dialogue in merged_cleaned_dialogues:\n",
    "        for dialogue_token in merged_cleaned_dialogue.split():\n",
    "            if dialogue_token.lower() == keyword.lower():\n",
    "                keyword_count += 1\n",
    "        keyword_count_list.append(keyword_count)\n",
    "        keyword_count = 0\n",
    "\n",
    "    return keyword_count_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function returns the number of vulgar words\n",
    "\n",
    "def count_vulgar_words(dialogues):\n",
    "    vulgar_words_list = ['anal', 'anus', 'ballsack', 'blowjob', 'boner', 'clitoris', 'cock', 'cunt',\n",
    "                         'dick', 'dildo', 'dyke', 'fag', 'fuck', 'jizz', 'labia', 'muff', 'nigger',\n",
    "                         'nigga', 'penis', 'piss', 'pussy', 'scrotum', 'sex', 'shit', 'slut',\n",
    "                         'smegma', 'spunk', 'twat', 'vagina', 'wank', 'whore']\n",
    "\n",
    "    vulgar_word_count_array = np.zeros(len(dialogues), dtype=int)\n",
    "\n",
    "    for vulgar_word in vulgar_words_list:\n",
    "        vulgar_word_count_array += np.array(count_keyword(dialogues, vulgar_word))\n",
    "\n",
    "    return list(vulgar_word_count_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function returns the number of keywords array\n",
    "\n",
    "def count_keywords(merged_cleaned_dialogues, keyword_list):\n",
    "    keywords_word_count_array = np.zeros(len(merged_cleaned_dialogues), dtype=int)\n",
    "\n",
    "    for keyword in keyword_list:\n",
    "        keywords_word_count_array += np.array(count_keyword(merged_cleaned_dialogues, keyword))\n",
    "\n",
    "    return list(keywords_word_count_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function returns the number of uppercase_words\n",
    "\n",
    "def extract_sequential_features(dialogues):\n",
    "    flag_inc_vulgar_words = []\n",
    "    vulgar_words_temp_list = []\n",
    "    flag_inc_uppercase_words = []\n",
    "    uppercase_words_temp_list = []\n",
    "    for dialogue in dialogues:\n",
    "        vulgar_words_temp_list = count_vulgar_words([dialogue['preceding_posts'][0]['body'],\n",
    "                                                     dialogue['preceding_posts'][1]['body']])\n",
    "        flag_inc_vulgar_words.append(1 if vulgar_words_temp_list[0] < vulgar_words_temp_list[1] else 0)\n",
    "        uppercase_words_temp_list = count_uppercase_words([dialogue['preceding_posts'][0]['body'],\n",
    "                                                           dialogue['preceding_posts'][1]['body']])\n",
    "        flag_inc_uppercase_words.append(1 if uppercase_words_temp_list[0] < uppercase_words_temp_list[1] else 0)\n",
    "\n",
    "    return flag_inc_vulgar_words, flag_inc_uppercase_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The top 150 features are taken from TfidfVectorizer\n",
    "\n",
    "def extract_tfidf_features(train_merged_cleaned_dialogues, test_merged_cleaned_dialogues, max_features):\n",
    "    tfidf = TfidfVectorizer(max_features=max_features, ngram_range=(1, 1))\n",
    "    train_tfidf_features = tfidf.fit_transform(train_merged_cleaned_dialogues)\n",
    "    train_tfidf_features_df = pd.DataFrame(train_tfidf_features.todense(),\n",
    "                                           columns=tfidf.get_feature_names())\n",
    "\n",
    "    test_tfidf_features = tfidf.transform(test_merged_cleaned_dialogues)\n",
    "    test_tfidf_features_df = pd.DataFrame(test_tfidf_features.todense(),\n",
    "                                          columns=tfidf.get_feature_names())\n",
    "\n",
    "    print(tfidf.get_feature_names())\n",
    "\n",
    "    return train_tfidf_features_df, test_tfidf_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function extracts the identified top features\n",
    "\n",
    "def extract_features(merged_cleaned_dialogues, dialogues):\n",
    "    features_df = pd.DataFrame()\n",
    "\n",
    "    features_df['no_of_uppercase_words'] = count_uppercase_words(merged_cleaned_dialogues)\n",
    "    features_df['no_of_nazi_words'] = count_keyword(merged_cleaned_dialogues, 'nazi')\n",
    "    features_df['no_of_rape_words'] = count_keyword(merged_cleaned_dialogues, 'rape')\n",
    "    features_df['no_of_racist_words'] = count_keyword(merged_cleaned_dialogues, 'racist')\n",
    "    features_df['no_of_propaganda_words'] = count_keyword(merged_cleaned_dialogues, 'propaganda')\n",
    "    features_df['no_of_vulgar_words'] = count_vulgar_words(merged_cleaned_dialogues)\n",
    "\n",
    "    features_df['no_of_missing_evidence_words'] = count_keywords(merged_cleaned_dialogues,\n",
    "                                                                 ['unsupported', 'unsubstantiated'])\n",
    "    features_df['no_of_fall_argument_words'] = count_keywords(merged_cleaned_dialogues,\n",
    "                                                              ['fallacy', 'fallacious'])\n",
    "    features_df['no_of_read_words'] = count_keywords(merged_cleaned_dialogues,\n",
    "                                                     ['reading', 'read'])\n",
    "    features_df['no_of_troll_words'] = count_keywords(merged_cleaned_dialogues,\n",
    "                                                      ['troll', 'trolls', 'trolling'])\n",
    "\n",
    "    features_df['flag_inc_vulgar_words'], features_df['flag_inc_uppercase_words'] = \\\n",
    "        extract_sequential_features(dialogues)\n",
    "\n",
    "    return features_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier Models Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have chosen the below classifiers and have trained them with the best hyperparameters.\n",
    "- Perceptron\n",
    "- Logistic Regression\n",
    "- NeuralNetworks(MLP)\n",
    "- SVM\n",
    "- Random Forest\n",
    "- kNearest Neighbour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks: MLPClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn_and_save_results(X_train, y_train, X_test, test_argument_id_list, nn_best_params_dict):\n",
    "    clf = MLPClassifier(**nn_best_params_dict)\n",
    "    clf.fit(X_train, y_train)\n",
    "    prediction_list = clf.predict(X_test)\n",
    "    prediction_list = [int(pred) for pred in prediction_list]\n",
    "\n",
    "    prediction_dict = {}\n",
    "    for index in range(len(prediction_list)):\n",
    "        prediction_dict[test_argument_id_list[index]] = prediction_list[index]\n",
    "\n",
    "    with open('predictions_neural_networks.json', 'w') as pred_file:\n",
    "        json.dump(prediction_dict, pred_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_perceptron_and_save_results(X_train, y_train, X_test, test_argument_id_list, perceptron_best_params_dict):\n",
    "    clf = Perceptron(**perceptron_best_params_dict)\n",
    "    clf.fit(X_train, y_train)\n",
    "    prediction_list = clf.predict(X_test)\n",
    "    prediction_list = [int(pred) for pred in prediction_list]\n",
    "\n",
    "    prediction_dict = {}\n",
    "    for index in range(len(prediction_list)):\n",
    "        prediction_dict[test_argument_id_list[index]] = prediction_list[index]\n",
    "\n",
    "    with open('predictions_perceptron.json', 'w') as pred_file:\n",
    "        json.dump(prediction_dict, pred_file, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighbors Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_kNN_and_save_results(X_train, y_train, X_test, test_argument_id_list, kNN_best_params_dict):\n",
    "    clf = KNeighborsClassifier(**kNN_best_params_dict)\n",
    "    clf.fit(X_train, y_train)\n",
    "    prediction_list = clf.predict(X_test)\n",
    "    prediction_list = [int(pred) for pred in prediction_list]\n",
    "\n",
    "    prediction_dict = {}\n",
    "    for index in range(len(prediction_list)):\n",
    "        prediction_dict[test_argument_id_list[index]] = prediction_list[index]\n",
    "\n",
    "    with open('predictions_kNN.json', 'w') as pred_file:\n",
    "        json.dump(prediction_dict, pred_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Classifier (SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm_and_save_results(X_train, y_train, X_test, test_argument_id_list, svm_best_params_dict):\n",
    "    clf = SVC(**svm_best_params_dict)\n",
    "    clf.fit(X_train, y_train)\n",
    "    prediction_list = clf.predict(X_test)\n",
    "    prediction_list = [int(pred) for pred in prediction_list]\n",
    "\n",
    "    prediction_dict = {}\n",
    "    for index in range(len(prediction_list)):\n",
    "        prediction_dict[test_argument_id_list[index]] = prediction_list[index]\n",
    "\n",
    "    with open('predictions_svm.json', 'w') as pred_file:\n",
    "        json.dump(prediction_dict, pred_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lr_and_save_results(X_train, y_train, X_test, test_argument_id_list, lr_best_params_dict):\n",
    "    clf = LogisticRegression(**lr_best_params_dict)\n",
    "    clf.fit(X_train, y_train)\n",
    "    prediction_list = clf.predict(X_test)\n",
    "    prediction_list = [int(pred) for pred in prediction_list]\n",
    "\n",
    "    prediction_dict = {}\n",
    "    for index in range(len(prediction_list)):\n",
    "        prediction_dict[test_argument_id_list[index]] = prediction_list[index]\n",
    "\n",
    "    with open('predictions_lr.json', 'w') as pred_file:\n",
    "        json.dump(prediction_dict, pred_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_random_forest_and_save_results(X_train, y_train, X_test, test_argument_id_list, random_forest_params_dict):\n",
    "    clf = RandomForestClassifier(**random_forest_params_dict)\n",
    "    clf.fit(X_train, y_train)\n",
    "    prediction_list = clf.predict(X_test)\n",
    "    prediction_list = [int(pred) for pred in prediction_list]\n",
    "\n",
    "    prediction_dict = {}\n",
    "    for index in range(len(prediction_list)):\n",
    "        prediction_dict[test_argument_id_list[index]] = prediction_list[index]\n",
    "\n",
    "    with open('predictions_random_forest.json', 'w') as pred_file:\n",
    "        json.dump(prediction_dict, pred_file, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim here is to optimize the hyperparameters (on the training dataset) used in the above mentioned classifiers. In this step, we perform a cross-validation on the training dataset and get the best hyperparameters for our classifiers. I have used GridSearchCV in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hp_optimize_perceptron(X_train, y_train):\n",
    "    param_grids = [\n",
    "        {\n",
    "            \"penalty\": [\"l2\", \"l1\", \"elasticnet\"],\n",
    "            \"alpha\": [0.0001, 0.001, 0.01, 0.1],\n",
    "            \"max_iter\": [1000, 1500, 2000, 2500, 3000]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    grid_clf = Perceptron()\n",
    "\n",
    "    grid_search = GridSearchCV(grid_clf, param_grid=param_grids, cv=3, n_jobs=-1\n",
    "                               , scoring=\"f1\")\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Perceptron best params:\" + str(grid_search.best_params_))\n",
    "    return grid_search.best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hp_optimize_kNN(X_train, y_train):\n",
    "    param_grids = [\n",
    "        {\n",
    "            \"n_neighbors\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    grid_clf = KNeighborsClassifier()\n",
    "\n",
    "    grid_search = GridSearchCV(grid_clf, param_grid=param_grids, cv=3, n_jobs=-1\n",
    "                               , scoring=\"f1\")\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print(\"kNN best params:\" + str(grid_search.best_params_))\n",
    "    return grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks: MLPClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hp_optimize_nn(X_train, y_train):\n",
    "    param_grids = [\n",
    "        {\n",
    "            \"alpha\": [0.0001, 0.001, 0.01, 0.1],\n",
    "            \"activation\": [\"logistic\", \"tanh\", \"relu\"],\n",
    "            \"max_iter\": [1500],\n",
    "            \"hidden_layer_sizes\": [(6, 4, 2), (6, 3)]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    grid_clf = MLPClassifier()\n",
    "\n",
    "    grid_search = GridSearchCV(grid_clf, param_grid=param_grids, cv=3, n_jobs=-1\n",
    "                               , scoring=\"f1\")\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print(\"NN best params:\" + str(grid_search.best_params_))\n",
    "    return grid_search.best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hp_optimize_svm(X_train, y_train):\n",
    "    param_grids = [\n",
    "        {\n",
    "            \"C\": [0.001, 0.01, 0.1, 1.0, 10.0, 100.0],\n",
    "            \"gamma\": [\"scale\"],\n",
    "            \"kernel\": [\"linear\", \"poly\", \"rbf\"]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    grid_clf = SVC()\n",
    "\n",
    "    grid_search = GridSearchCV(grid_clf, param_grid=param_grids, cv=3, n_jobs=-1\n",
    "                               , scoring=\"f1\")\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print(\"SVM best params:\" + str(grid_search.best_params_))\n",
    "    return grid_search.best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hp_optimize_lr(X_train, y_train):\n",
    "    param_grids = [\n",
    "        {\n",
    "            \"C\": [0.001, 0.01, 0.1, 1.0, 10.0, 100.0],\n",
    "            \"max_iter\": [300, 400, 500]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    grid_clf = LogisticRegression()\n",
    "\n",
    "    grid_search = GridSearchCV(grid_clf, param_grid=param_grids, cv=3, n_jobs=-1\n",
    "                               , scoring=\"f1\")\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Logistic Regression best params:\" + str(grid_search.best_params_))\n",
    "    return grid_search.best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hp_optimize_random_forest(X_train, y_train):\n",
    "    param_grids = [\n",
    "        {\n",
    "            \"n_estimators\": [25, 50, 75, 100]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    grid_clf = RandomForestClassifier()\n",
    "\n",
    "    grid_search = GridSearchCV(grid_clf, param_grid=param_grids, cv=3, n_jobs=-1\n",
    "                               , scoring=\"f1\")\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Random Forest best params:\" + str(grid_search.best_params_))\n",
    "    return grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['able', 'absolutely', 'actually', 'agree', 'argue', 'argument', 'away', 'bad', 'based', 'believe', 'best', 'better', 'black', 'care', 'case', 'change', 'child', 'children', 'claim', 'come', 'comment', 'completely', 'country', 'course', 'culture', 'day', 'definition', 'different', 'discussion', 'end', 'etc', 'evidence', 'exactly', 'example', 'experience', 'fact', 'far', 'feel', 'find', 'free', 'gender', 'getting', 'going', 'good', 'got', 'government', 'group', 'hard', 'having', 'help', 'human', 'idea', 'important', 'instead', 'issue', 'job', 'kill', 'kind', 'know', 'law', 'let', 'life', 'like', 'likely', 'literally', 'little', 'live', 'long', 'look', 'lot', 'majority', 'makes', 'making', 'man', 'matter', 'maybe', 'mean', 'means', 'men', 'money', 'need', 'new', 'non', 'nt', 'op', 'opinion', 'pay', 'people', 'person', 'personal', 'place', 'point', 'political', 'poor', 'post', 'power', 'pretty', 'probably', 'problem', 'public', 'question', 'racist', 'rape', 'read', 'real', 'reason', 'right', 'rights', 'said', 'saying', 'self', 'sense', 'sex', 'shit', 'simply', 'single', 'social', 'society', 'state', 'stop', 'support', 'sure', 'system', 'talking', 'tell', 'thing', 'things', 'think', 'time', 'trans', 'true', 'trump', 'try', 'trying', 'understand', 'use', 'view', 'want', 'war', 'way', 'white', 'wo', 'woman', 'women', 'word', 'work', 'world', 'wrong', 'years', 'yes']\n",
      "      no_of_uppercase_words  no_of_nazi_words  no_of_rape_words  \\\n",
      "0                         1                 0                 0   \n",
      "1                         0                 0                 0   \n",
      "2                         0                 0                 0   \n",
      "3                         0                 0                 0   \n",
      "4                         1                 0                 0   \n",
      "...                     ...               ...               ...   \n",
      "1931                     20                 0                 0   \n",
      "1932                      1                 0                 0   \n",
      "1933                      0                 0                 0   \n",
      "1934                      1                 0                 0   \n",
      "1935                      0                 0                 0   \n",
      "\n",
      "      no_of_racist_words  no_of_propaganda_words  no_of_vulgar_words  \\\n",
      "0                      0                       0                   4   \n",
      "1                      0                       0                   0   \n",
      "2                      0                       0                   0   \n",
      "3                      0                       0                   0   \n",
      "4                      0                       0                   0   \n",
      "...                  ...                     ...                 ...   \n",
      "1931                   0                       0                   0   \n",
      "1932                   0                       0                   0   \n",
      "1933                   0                       0                   0   \n",
      "1934                   0                       0                   0   \n",
      "1935                   0                       0                   0   \n",
      "\n",
      "      no_of_missing_evidence_words  no_of_fall_argument_words  \\\n",
      "0                                0                          0   \n",
      "1                                0                          0   \n",
      "2                                0                          0   \n",
      "3                                0                          0   \n",
      "4                                0                          0   \n",
      "...                            ...                        ...   \n",
      "1931                             0                          0   \n",
      "1932                             0                          0   \n",
      "1933                             0                          0   \n",
      "1934                             0                          0   \n",
      "1935                             0                          0   \n",
      "\n",
      "      no_of_read_words  no_of_troll_words  ...  white       wo     woman  \\\n",
      "0                    0                  0  ...    0.0  0.00000  0.176401   \n",
      "1                    1                  0  ...    0.0  0.00000  0.000000   \n",
      "2                    8                  0  ...    0.0  0.00000  0.000000   \n",
      "3                    5                  0  ...    0.0  0.00000  0.000000   \n",
      "4                    0                  0  ...    0.0  0.00000  0.000000   \n",
      "...                ...                ...  ...    ...      ...       ...   \n",
      "1931                 0                  0  ...    0.0  0.00000  0.000000   \n",
      "1932                 2                  0  ...    0.0  0.00000  0.000000   \n",
      "1933                 0                  0  ...    0.0  0.22607  0.000000   \n",
      "1934                 0                  0  ...    0.0  0.00000  0.000000   \n",
      "1935                 0                  0  ...    0.0  0.00000  0.000000   \n",
      "\n",
      "         women  word  work     world     wrong     years  yes  \n",
      "0     0.307956   0.0   0.0  0.140074  0.000000  0.000000  0.0  \n",
      "1     0.418482   0.0   0.0  0.380692  0.000000  0.000000  0.0  \n",
      "2     0.000000   0.0   0.0  0.000000  0.000000  0.113902  0.0  \n",
      "3     0.000000   0.0   0.0  0.000000  0.050275  0.123665  0.0  \n",
      "4     0.000000   0.0   0.0  0.000000  0.000000  0.000000  0.0  \n",
      "...        ...   ...   ...       ...       ...       ...  ...  \n",
      "1931  0.000000   0.0   0.0  0.000000  0.037597  0.046240  0.0  \n",
      "1932  0.000000   0.0   0.0  0.088367  0.161454  0.000000  0.0  \n",
      "1933  0.000000   0.0   0.0  0.000000  0.088495  0.000000  0.0  \n",
      "1934  0.000000   0.0   0.0  0.000000  0.000000  0.000000  0.0  \n",
      "1935  0.000000   0.0   0.0  0.000000  0.000000  0.000000  0.0  \n",
      "\n",
      "[1936 rows x 162 columns]\n",
      "0       1\n",
      "1       0\n",
      "2       1\n",
      "3       0\n",
      "4       1\n",
      "       ..\n",
      "1931    0\n",
      "1932    1\n",
      "1933    0\n",
      "1934    1\n",
      "1935    0\n",
      "Length: 1936, dtype: int32\n",
      "      no_of_uppercase_words  no_of_nazi_words  no_of_rape_words  \\\n",
      "0                         1                 0                 0   \n",
      "1                         0                 0                 0   \n",
      "2                         0                 0                 0   \n",
      "3                         0                 0                 0   \n",
      "4                         1                 0                 0   \n",
      "...                     ...               ...               ...   \n",
      "1931                     20                 0                 0   \n",
      "1932                      1                 0                 0   \n",
      "1933                      0                 0                 0   \n",
      "1934                      1                 0                 0   \n",
      "1935                      0                 0                 0   \n",
      "\n",
      "      no_of_racist_words  no_of_propaganda_words  no_of_vulgar_words  \\\n",
      "0                      0                       0                   4   \n",
      "1                      0                       0                   0   \n",
      "2                      0                       0                   0   \n",
      "3                      0                       0                   0   \n",
      "4                      0                       0                   0   \n",
      "...                  ...                     ...                 ...   \n",
      "1931                   0                       0                   0   \n",
      "1932                   0                       0                   0   \n",
      "1933                   0                       0                   0   \n",
      "1934                   0                       0                   0   \n",
      "1935                   0                       0                   0   \n",
      "\n",
      "      no_of_missing_evidence_words  no_of_fall_argument_words  \\\n",
      "0                                0                          0   \n",
      "1                                0                          0   \n",
      "2                                0                          0   \n",
      "3                                0                          0   \n",
      "4                                0                          0   \n",
      "...                            ...                        ...   \n",
      "1931                             0                          0   \n",
      "1932                             0                          0   \n",
      "1933                             0                          0   \n",
      "1934                             0                          0   \n",
      "1935                             0                          0   \n",
      "\n",
      "      no_of_read_words  no_of_troll_words  ...  white       wo     woman  \\\n",
      "0                    0                  0  ...    0.0  0.00000  0.176401   \n",
      "1                    1                  0  ...    0.0  0.00000  0.000000   \n",
      "2                    8                  0  ...    0.0  0.00000  0.000000   \n",
      "3                    5                  0  ...    0.0  0.00000  0.000000   \n",
      "4                    0                  0  ...    0.0  0.00000  0.000000   \n",
      "...                ...                ...  ...    ...      ...       ...   \n",
      "1931                 0                  0  ...    0.0  0.00000  0.000000   \n",
      "1932                 2                  0  ...    0.0  0.00000  0.000000   \n",
      "1933                 0                  0  ...    0.0  0.22607  0.000000   \n",
      "1934                 0                  0  ...    0.0  0.00000  0.000000   \n",
      "1935                 0                  0  ...    0.0  0.00000  0.000000   \n",
      "\n",
      "         women  word  work     world     wrong     years  yes  \n",
      "0     0.307956   0.0   0.0  0.140074  0.000000  0.000000  0.0  \n",
      "1     0.418482   0.0   0.0  0.380692  0.000000  0.000000  0.0  \n",
      "2     0.000000   0.0   0.0  0.000000  0.000000  0.113902  0.0  \n",
      "3     0.000000   0.0   0.0  0.000000  0.050275  0.123665  0.0  \n",
      "4     0.000000   0.0   0.0  0.000000  0.000000  0.000000  0.0  \n",
      "...        ...   ...   ...       ...       ...       ...  ...  \n",
      "1931  0.000000   0.0   0.0  0.000000  0.037597  0.046240  0.0  \n",
      "1932  0.000000   0.0   0.0  0.088367  0.161454  0.000000  0.0  \n",
      "1933  0.000000   0.0   0.0  0.000000  0.088495  0.000000  0.0  \n",
      "1934  0.000000   0.0   0.0  0.000000  0.000000  0.000000  0.0  \n",
      "1935  0.000000   0.0   0.0  0.000000  0.000000  0.000000  0.0  \n",
      "\n",
      "[1936 rows x 162 columns]\n",
      "0       1\n",
      "1       0\n",
      "2       1\n",
      "3       0\n",
      "4       1\n",
      "       ..\n",
      "1931    0\n",
      "1932    1\n",
      "1933    0\n",
      "1934    1\n",
      "1935    0\n",
      "Length: 1936, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "train_dialogues = read_data_file('C:/Users/Amruta/Desktop/MLBoot/train-data-prepared.json')\n",
    "train_merged_cleaned_dialogues = preprocess_text_data(merge_dialogue_texts(train_dialogues))\n",
    "\n",
    "X_train = extract_features(train_merged_cleaned_dialogues, train_dialogues)\n",
    "y_train = pd.Series(data=np.array([dialogue['label'] for dialogue in train_dialogues]))\n",
    "\n",
    "test_file_path = sys.argv[1]\n",
    "\n",
    "test_dialogues = read_data_file(test_file_path)\n",
    "test_merged_cleaned_dialogues = preprocess_text_data(merge_dialogue_texts(test_dialogues))\n",
    "\n",
    "X_test = extract_features(test_merged_cleaned_dialogues, test_dialogues)\n",
    "y_test = pd.Series(data=np.array([dialogue['label'] for dialogue in test_dialogues]))\n",
    "\n",
    "train_tfidf_features_df, test_tfidf_features_df = extract_tfidf_features(train_merged_cleaned_dialogues,\n",
    "                                                                         test_merged_cleaned_dialogues, 150)\n",
    "\n",
    "X_train = pd.concat([X_train, train_tfidf_features_df], axis=1)\n",
    "X_test = pd.concat([X_test, test_tfidf_features_df], axis=1)\n",
    "\n",
    "print(X_train)\n",
    "print(y_train)\n",
    "print(X_test)\n",
    "print(y_test)\n",
    "\n",
    "test_id_list = [dialogue['id'] for dialogue in test_dialogues]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters for each trained classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron best params:{'alpha': 0.0001, 'max_iter': 1000, 'penalty': 'l1'}\n",
      "NN best params:{'activation': 'logistic', 'alpha': 0.1, 'hidden_layer_sizes': (6, 4, 2), 'max_iter': 1500}\n",
      "kNN best params:{'n_neighbors': 5}\n",
      "SVM best params:{'C': 100.0, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Logistic Regression best params:{'C': 10.0, 'max_iter': 300}\n",
      "Random Forest best params:{'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Perceptron\n",
    "perceptron_best_params_dict = hp_optimize_perceptron(X_train, y_train)\n",
    "train_perceptron_and_save_results(X_train, y_train, X_test, test_id_list, perceptron_best_params_dict)\n",
    "\n",
    "# Neural Netwroks: MLP Classifier\n",
    "nn_best_params_dict = hp_optimize_nn(X_train, y_train)\n",
    "train_nn_and_save_results(X_train, y_train, X_test, test_id_list, nn_best_params_dict)\n",
    "\n",
    "# KNeigbors Classifier\n",
    "kNN_best_params_dict = hp_optimize_kNN(X_train, y_train)\n",
    "train_kNN_and_save_results(X_train, y_train, X_test, test_id_list, kNN_best_params_dict)\n",
    "\n",
    "# SVM \n",
    "svm_best_params_dict = hp_optimize_svm(X_train, y_train)\n",
    "train_svm_and_save_results(X_train, y_train, X_test, test_id_list, svm_best_params_dict)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_best_params_dict = hp_optimize_lr(X_train, y_train)\n",
    "train_lr_and_save_results(X_train, y_train, X_test, test_id_list, lr_best_params_dict)\n",
    "\n",
    "# Random Forest Classifier\n",
    "random_forest_params_dict = hp_optimize_random_forest(X_train, y_train)\n",
    "train_random_forest_and_save_results(X_train, y_train, X_test, test_id_list, random_forest_params_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running above cells, the predictions file “predictions_(name_of_classifier).json” will be generated in the main folder which will contain all the predictions for the desired test file. I have created an evaluation python script as well to check the prediction f1 score for the desired test file. <br> \n",
    "\n",
    "Run the evaluation script on training data using the following command:<br>\n",
    "*$ python eval.py -t (path-to-ground-truth-file)  -p   (path-to-predictions-file)*\n",
    "\n",
    "Example:<br>\n",
    " *$ python eval.py -t train-data-prepared.json -p predictions_svm.json*\n",
    " \n",
    " Similarily, run the eval script on validation data using the following command : <br>\n",
    " *$ python eval.py -t (path-to-ground-truth-file)  -p   (path-to-predictions-file)*\n",
    " \n",
    " Example:<br>\n",
    " *$ python eval.py -t val-data-prepared.json -p predictions_svm.json*"
   ]
  },
 }
